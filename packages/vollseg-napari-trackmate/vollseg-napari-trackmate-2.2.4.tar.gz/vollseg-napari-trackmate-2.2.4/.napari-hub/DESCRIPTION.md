# Description

This GUI plugin allows you to do track analysis by using autoencoder models that convert the segmentation labels to point cloud representations. It takes
a TrackMate generated XML and csv files and creates a master XML file by computing additional shape and dynamic features based on the generated point clouds. 




# Who is This For?

This plugin is intended to be used on 3D+time tracking data for researchers interested in performing cell-fate analysis for which the shape and dynamic features of cells in a track are relevant.

# How to Guide

You will need to have a segmentation image in 3D generated by VollSeg or other such plugins along with tracking XML, spots, edges and tracks csv file 
generated from the Fiji plugin TrackMate. You can either use our autoencoder models to apply on your segmentation image to generate point cloud representations
or upload your torch trained model based on our Lightning based package [Lightning version](https://github.com/Kapoorlabs-CAPED/KapoorLabs-Lightning).



# Getting Help

If you find a bug with affinder, or would like support with using it, please raise an
issue on the [GitHub repository](https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate).

# How to Cite

Please use the following citations if you use this in your work:


@InProceedings{ varun_kapoor-proc-scipy-2021,
  author    = { {V}arun {K}apoor and {C}laudia {C}araba\~na },
  title     = { {C}ell {T}racking in 3{D} using deep learning segmentations },
  booktitle = { {P}roceedings of the 20th {P}ython in {S}cience {C}onference },
  pages     = { 154 - 161 },
  year      = { 2021 },
  editor    = { {M}eghann {A}garwal and {C}hris {C}alloway and {D}illon {N}iederhut and {D}avid {S}hupe },
  doi       = { 10.25080/majora-1b6fd038-014 }
}
