{% extends "timeline-page.html" %}

{% block stylesheets %}
    <link rel="stylesheet" href="/static/css/consent.css"/>
{% endblock %}

{% block main_body %}
  <div class="main-div" style="padding-bottom: 100px;">
    <noscript>
        <h1>Warning: Javascript is not working on your browser</h1>
        <p>The study will not work unless Javascript is enabled on your browser.</p>
        <p>Please enable Javascript then refresh this page.</p>
    </noscript>
    <h1>We need your consent to proceed</h1>
    <hr>
    <div class="text-justify">
        <div class="text-left" style="font-size:18px">
            <h2>Overview</h2>
            <p>
                This research is being conducted by researchers at the
                Max-Planck-Institute for Empirical Aesthetics. In case of questions you
                can contact <a href="mailto:{{contact_email_on_error}}">
                {{contact_email_on_error}}</a>.
            </p>
            <p>
                The purpose of this online form is to give you information to help you
                decide whether you want to take part in a research study. This online
                consent form includes the following information:
            </p>
            <ol>
                <li> Purpose of the study.</li>
                <li> Why the study is being done.</li>
                <li> The things that you will be asked to do if you are in the study.</li>
                <li> Any known risks involved.</li>
                <li> Any potential benefits.</li>
            </ol>

            <h2>Purpose</h2>
            <p>
                The purpose of this project is to characterize internal representations in
                audition and vision. Specifically, we would like to understand how
                predictive mechanisms in perception rely on experience, learning and memory.
                We hope to use the judgments and interactions made by the experiment
                participants to infer the mechanisms of the auditory and visual systems. The
                long-term goals of this project are to understand how humans derive
                information from sound and vision, and potentially to help engineer machines
                that can replicate our abilities (e.g. in sound/image recognition and computer
                vision) and to help improve perceptual abilities in people whose hearing or
                sight is impaired.
            </p>

            <h2>Procedure</h2>
            <p>
                If you volunteer to participate in this study, you will be asked to perform
                simple tasks using your keyboard or mouse while listening to sounds, or while
                observing images or videos. For example, you may be asked to judge how
                pleasant a particular sound or an image is, or to categorize sounds or
                images (e.g., if a sound or an image is that of a car or a cow), or to judge
                other basic features of sounds or images (e.g., how frequently do you
                encounter this type of sound or image? how aesthetically pleasing you
                consider a particular sound or image?). The specific sounds, images, and
                videos used will vary, but may include: recordings of ambient sounds,
                noise-bursts, speech, music, simple tones, naturalistic images, animated
                images, comics, faces, objects, geometric shapes, fractal images, or videos
                of natural environments. In some cases, you may be asked to make a voice or
                video recording, for example, you may be asked to record your finger-tapping
                in response to a sound or video, or to record yourself speaking or singing.
                If the experiment will contain these elements we will ask for an additional
                consent, consenting to these additional elements is voluntary.
            </p>
            <p>
                In some experiments, we may use mild deception, i.e., we may not explain the
                full truth regarding an experimental task (for example we will not tell you
                that an image was generated by an artificial computer system and not a human).
                Mild deception will only be used in some experiments where we need to prevent
                biasing the participants before taking the experiment. The experiment will
                take you approximately <span style="font-weight: bold; white-space: nowrap;">
                {{ experiment.estimated_duration_in_minutes|round|int }} minutes</span>
                to complete.
            </p>

            <h2>Voluntary participation</h2>
            <p>
                Your participation in this research is voluntary. You are free to refuse to
                take part, and you may stop taking part at any time. You are free to
                discontinue participation in this study at any time without penalty. The
                investigator may withdraw you from this research if circumstances arise
                which warrant doing so.
            </p>

            <h2>Confidentiality</h2>
            <p>
                No personal identifiers (e.g. your name or contact data) will be collected
                or used at any stage of the experiment. Thus, the experimental data is
                anonymous.
            </p>
            <p>
                We will also collect some demographic data (e.g. age, gender, country of
                residence) as well as information about your learning and exposure history
                (e.g. musical experience playing an instrument, years of formal education,
                languages spoken).
            </p>
            <p>
                All of the information we obtain during the research will be kept confidential.
                We will only save your anonymized Amazon’s Mechanical Turk IDs in our system,
                in order to distinguish participants who have already taken part on this or
                other experiments. MTurk worker IDs will not be used to derive your real
                identity, will not be shared with anyone outside of the research team and will
                be deleted after use.
            </p>
            <p>
                We will only share with collaborators demographic, aggregated or extracted data
                without personal identifiers (not indexed by Amazon’s Mechanical Turk IDs).
            </p>
            <p>
                The data for this study will be stored in a confidential manner for a duration
                of 10 years for the purpose of helping scientific replications. Anonymized data
                could be published in open access data repository accompanying publications of
                the study.
            </p>

            <h2>Security</h2>
            <p>
                Data will be stored temporarily on external servers and desktops/laptops
                that are password protected. The data will be then stored permanently in
                the institute servers with hard disks
                encrypted using industry-standard encryption software. No data will be
                stored permanently on external servers. Theft of an individual
                laptop/desktop or stolen hard drive will yield no usable personal
                identifiers. All backup hard drives (Apple Time Machine, etc) will have
                encryption (FileVault2) enabled. All USB keys used for transporting
                protected data will be encrypted USB devices.
            </p>

            <h2>Risks / discomforts </h2>
            <p>
                There are no risks for participating in this study beyond those associated
                with normal computer use.
            </p>

            <h2>Benefits</h2>
            <p>
                Although it may not directly benefit you, this study may benefit society by
                helping us understanding how humans derive information from sound and
                vision, and potentially to help engineer machines that can replicate our
                abilities (e.g. in sound recognition and computer vision) and to help
                improve perceptual abilities in people whose hearing or sight is impaired.
            </p>

            <h2>Compensation</h2>
            <p>
                If you satisfactorily complete the study, you will receive approximately
                <span style="font-weight: bold; white-space: nowrap;">
                ${{ "{:.2f}".format(experiment.var.wage_per_hour) }} per hour</span> to
                compensate you for your participation.
            </p>

            <h2>Disclaimer</h2>
            <p>
                Although researchers will not use your MTurk ID to derive your real
                identity, your MTurk ID could be linked to your Amazon public profile page
                if a data breach takes place. Thus, you may wish to restrict what
                information you choose to share publicly.
            </p>

            <h2>Your rights</h2>
            <p>
                You have the right to information regarding the data relating to you that is
                stored at the Max-Planck-Institute, the right to correct inaccurate data,
                and the right to demand the deletion of data in cases of inadmissible data
                storage and the right to data portability. You also have the right to submit
                an objection to the supervisory authority. For the Max-Planck-Society, this
                is the Bayerische Landesamt für Datenschutzaufsicht, Postfach 606, 91511
                Ansbach, Germany.
            </p>

            <h2> Contact information </h2>
            <p>
                If you have any questions about this research, do not hesitate to contact <a href="mailto:{{contact_email_on_error}}">{{contact_email_on_error}}</a>.
                If you have any questions about your rights or treatment as a participant in
                this research project, please contact (nori.jacoby@ae.mpg.de).
            </p>

            <h2> Consent </h2>
            <p>
                By consenting to participate, you acknowledge that you are 18 years or
                older, have read this consent form, agree to its contents, and agree to take
                part in this research. If you do not wish to consent, please close this page
                and return the HIT on Mechanical Turk.
            </p>
        </div>
        <hr>
        <h4>Do you understand and consent to these terms?</h4>
        <br>
        <button type="button" class="btn btn-primary btn-lg" id="consent" onClick="psynet.nextPage(true);" style="float: left;">
            I agree
        </button>
        <button type="button" class="btn btn-danger btn-lg" onClick="psynet.nextPage(false);" style="float: right;">
          No, thank you (return task)
        </button>
      </div>
  </div>
{% endblock %}
